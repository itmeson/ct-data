Week 2  
######

:date: 2018-12-01
:summary: Digging into introductory programming and data analysis
:category: weeks
:tags: data, intro, ct, principles


=====
Day 1
=====


 1. The rainfall problem: Use the `project 2 link <https://classroom.github.com/a/puWUIi9I>`_ to get access to the second project.  You will have to:

   * Accept the assignment invitation by following the link
   * Open gitkraken, then clone the new reposity for project2, storing it in a local folder
   * Run anaconda navigator, then jupyter lab
   * Navigate to the folder you stored the new repository in using the file browser in jupyter lab, then open the file **rainfall.ipynb**
   * Do the work on that file, some of which we will do together and some independently.
   * Save the file when you are finished
   * Stage, commit, and push the changes using gitkraken

 2. We will talk through this program together and you will (eventually) be assessed on understanding what it does and how to write it yourself -- the basic idea is to write a program that accepts user input for daily rainfall and computes the running average over time.


 3. Depending on time and where everyone is in this assignment sequence, we will watch the following video on day 1 or day 2.

.. raw:: html

  <iframe width="100%" height="480" src="https://www.youtube.com/embed/qrhRfPY4F4w" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>



=====
Day 2
=====

 1. The core big ideas of computational thinking are:

    * Decomposition -- breaking up complexity into simple parts
    * Patterns -- recognizing and making use of repetition
    * Abstraction -- generalizing and simplifying
    * Algorithms -- design and analysis of problem-solving procedures

 2. For example, our program to compute the average rainfall makes use of a pattern called the "accumulator" where it adds up the rainfall values and then divides by the number of data points.  There's more than way to accomplish this goal, and this goal is useful in a lot of situations -- so if there is a way to streamline and simplify the accumulation and division steps, so you don't have to write them all explicitly, then you are more likely to write successful programs without bugs.

 3. Another kind of thing we want to do with data is to **filter** it, taking into consideration only certain values.  For example, in the first project we filtered the data to show only projection data for one political party at a time.  This can be done in several ways, but at it's most basic level a filter is looking at all the data and **if** it matches some criteria it is used in one way, and otherwise (**elif**) it is used in another way.

 4. Our third project will explore national housing price data gathered by Zillow over the last 22 years:

   * Accept the assignment by using the `project 3 link <https://classroom.github.com/a/oPjkCwd6>`_
   * Open gitkraken, then clone the new reposity for project3, storing it in a local folder
   * Run anaconda navigator, then jupyter lab
   * Navigate to the folder you stored the new repository in using the file browser in jupyter lab, then open the file **explore_housing.ipynb** from the **code** folder.
   * Do the work on that file, some of which we will do together and some independently. The instructions are in the Readme.md file and in the explore_housing notebook.
   * Save the file when you are finished
   * Stage, commit, and push the changes using gitkraken




=====
Day 3
=====

 1. Completing the rainfall project and the housing price data project

 2. Debriefing some big ideas we've seen in the first two weeks

 3. Possibly a video and/or discussion, surveys on how it's going so far.


   
